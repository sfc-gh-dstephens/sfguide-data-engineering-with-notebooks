{
  "metadata": {
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c1970118-7b46-4dcf-acd2-cd8836d14408",
      "metadata": {
        "name": "md_overview",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Load Excel Files\n\n* Author: Dexter Stephens\n* Last Updated: 11/28/2024\n\nThis notebook will load data into the `TRANSACTION`, `COMPANY` and `PRESS_AND_EARNINGS` tables from Excel files."
    },
    {
      "cell_type": "code",
      "id": "8873bc96-287b-4f47-a929-013c1487a088",
      "metadata": {
        "language": "sql",
        "name": "sql_get_context",
        "resultVariableName": "dataframe_1"
      },
      "outputs": [],
      "source": "-- This won't be needed when we can pass variables to Notebooks!\nSELECT current_database() AS DATABASE_NAME, current_schema() AS SCHEMA_NAME",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "3775908f-ca36-4846-8f38-5adca39217f2",
      "metadata": {
        "language": "python",
        "name": "py_imports",
        "collapsed": false
      },
      "source": "# Import python packages\nimport logging\nimport pandas as pd\n\nlogger = logging.getLogger(\"demo_logger\")\n\n# Get the target database and schema using the results from the SQL cell above\n# This won't be needed when we can pass variables to Notebooks!\ncurrent_context_df = cells.sql_get_context.to_pandas()\ndatabase_name = current_context_df.iloc[0,0]\nschema_name = current_context_df.iloc[0,1]\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n#session.use_schema(f\"{database_name}.{schema_name}\")\n\nlogger.info(\"load_excel_files start\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "413fad43-3fec-4379-b34b-7e1728599a7a",
      "metadata": {
        "language": "sql",
        "name": "sql_get_spreadsheets",
        "collapsed": false,
        "resultVariableName": "dataframe_2"
      },
      "outputs": [],
      "source": "SELECT \n    '@INTEGRATIONS.FINANCIAL_DATA_RAW_STAGE/' || RELATIVE_PATH as STAGE_FILE_PATH,\n    SPLIT_PART(RELATIVE_PATH, '/', 1) AS TARGET_TABLE\nFROM DIRECTORY(@INTEGRATIONS.FINANCIAL_DATA_RAW_STAGE)",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "07fd7441-1c12-4195-a7cd-f04fcc3e4242",
      "metadata": {
        "name": "md_function",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Create a function to load Excel worksheet to table\n\nCreate a reusable function to load an Excel worksheet to a table in Snowflake."
    },
    {
      "cell_type": "code",
      "id": "d92d7957-762a-49ae-95e6-8b407ddba0f6",
      "metadata": {
        "language": "python",
        "name": "py_load_excel_function",
        "collapsed": false
      },
      "outputs": [],
      "source": "import os\nfrom snowflake.snowpark.files import SnowflakeFile\nfrom openpyxl import load_workbook\nfrom snowflake.snowpark.types import VariantType\nfrom snowflake.snowpark.functions import col, to_variant\n\ndef load_excel_worksheet_to_table(session, stage_file_path, target_table): \n    with SnowflakeFile.open(stage_file_path, 'rb') as f:\n        workbook = load_workbook(f)\n        sheet = workbook.active\n        data = sheet.values\n        columns = next(data)[0:]\n        df = pd.DataFrame(data, columns=columns)\n        \n        df2 = session.create_dataframe(df)\n        df2.write.mode(\"overwrite\").save_as_table(target_table)\n    \n    return True",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "97c2fc79-50d4-4a81-af5d-5c80d37070ec",
      "metadata": {
        "name": "md_process_spreadsheets",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Process all Excel worksheets\n\nLoop through each Excel worksheet to process and call our `load_excel_worksheet_to_table_local()` function."
    },
    {
      "cell_type": "code",
      "id": "4e73f895-6b24-4ce9-b357-7a9a879be1e4",
      "metadata": {
        "language": "python",
        "name": "py_process_spreadsheets"
      },
      "outputs": [],
      "source": "# Process each file from the sql_get_spreadsheets cell above\nfiles_to_load = cells.sql_get_spreadsheets.to_pandas()\nfor index, excel_file in files_to_load.iterrows():\n    logger.info(f\"Processing Excel file {excel_file['STAGE_FILE_PATH']}\")\n    load_excel_worksheet_to_table(session, excel_file['STAGE_FILE_PATH'], excel_file['TARGET_TABLE'])\n\nlogger.info(\"load_excel_files end\")",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "16d6be04-3690-4c5d-91ee-5d0d425355b8",
      "metadata": {
        "name": "md_debugging",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Debugging"
    },
    {
      "cell_type": "code",
      "id": "a878dd75-f426-427f-bbef-e5401097d9d6",
      "metadata": {
        "language": "sql",
        "name": "sql_debugging",
        "resultVariableName": "dataframe_3"
      },
      "outputs": [],
      "source": "--DESCRIBE TABLE TRANSACTIONS;\n--SELECT * FROM TRANSACTIONS;\n--SHOW TABLES;",
      "execution_count": null
    }
  ]
}